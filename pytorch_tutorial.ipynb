{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMP6RDebKp5kbgMS4bZX6k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ssungni/Algorithm/blob/main/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "oyR9Z03ME59_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# torch라고 하는 프로그래밍 언어가 먼저 나옴,\n",
        "# 루아(Lua)라고 구현된 토치 라이브러리에 파이썬을 적용해서 API -> pytorch\n",
        "\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "# \"torch.utils.data.DataLoader\"과 같이 매번 써주는 게 쉽지 않으므로\n",
        "DataLoader # 나는 DataLoader로 쓸거야!!\n",
        "\n",
        "from torchvision import datasets # 파이토치에서 사용하는 컴퓨터 비전들이 굉장히 많이 구현되어 있음\n",
        "# 이러한 datasets를 관리하는 transforms에 Tensor\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# datasets -> FashionMNIST -> training data, test data를 불러오는 과정\n",
        "\n",
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True, # FashionMNIST에는 train 데이터, test 데이터가 있으며 그 중 train (o)\n",
        "    download=True, # if 다운로드를 안 했으면 다운로드를 하여라\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2Py8KeJNuiv",
        "outputId": "0509dc58-e0f3-4548-cd63-a993761cdf27"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 11686293.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 207459.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3893346.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 4807899.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataloader => 데이터로더가 데이터를 64개씩 묶어서 처리하도록\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size = batch_size)\n",
        "\n",
        "for X, y in test_dataloader: # X: 데이터(ex) 이미지), y: 데이터에 대한 레이블(ex) 고양이, 강아지)\n",
        "  print(\"Shape of X (N, C, H, W): \", X.shape) # 4차원 N: Number(수), C: Channel(채널의 길이), H: High(높이), W: Width(가로)\n",
        "  print(\"Shape of y : \", y.shape, y.dtype) # 1차원\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XH2eeZzRQDZl",
        "outputId": "c52fc536-d69e-449b-cb29-66f4260be513"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X (N, C, H, W):  torch.Size([64, 1, 28, 28])\n",
            "Shape of y :  torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # cuda란, NVIDIA에서 개발한 GPU 개발 툴\n",
        "print(\"Using {} device\".format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jj-9vhd_Ug5s",
        "outputId": "2dd10fc7-a09d-48e0-d487-002ae311f8f5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating model\n",
        "class NeuralNetwork(nn.Module):\n",
        "# nn.Module라는 부모 클래스 or 슈퍼 클래스로부터 상속을 받아 NeuralNetwork를 만들거임\n",
        "# nn.Module을 받는 다는 건 이미 초기화도 되어 있고, 정의가 되어 있지만\n",
        "# 우리가 재 정의할 수 있다!\n",
        "\n",
        "    def __init__(self): # 초기화\n",
        "        super(NeuralNetwork, self).__init__() # super 클래스를 먼저 초기화\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential( # Sequential하다는 것은 Linear, ReLU 를 다음과 같이 반복하는\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x): # 방법 재정의, 실행은 train 함수에서\n",
        "        x = self.flatten(x) # (flatten): Flatten(start_dim=1, end_dim=-1)\n",
        "        logits = self.linear_relu_stack(x) # Linear, ReLU\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)\n",
        "# 64개를 모은 결과, 최종 feature가 10개이어야 함."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FnISm4OsTDW8",
        "outputId": "d09022b1-c763-4a8c-98c1-3e8f4a44933b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "926NURaBXqnv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 실행\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device) # 사전에 어디에 올릴지 정의하고 해야\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)  # model(X) -> forward 함수를 정의해라 => nn.module에 다 있음\n",
        "        loss = loss_fn(pred, y) # 얼마나 비슷해? 얼마나 정확해?\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step() # 어느 지점에서 어떻게 내려왔어\n",
        "\n",
        "        if batch % 100 == 0: # 100번에 한 번씩 프린트를 해라! 얼마만큼 되었는\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ],
      "metadata": {
        "id": "36wGFScPYQI4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(dataloader, model):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "tFnHdqgEpJ1b"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5 # 100번에 한 번, 한 번 = 64회 그러므로 6400씩일 때\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model)\n",
        "print(\"Done!\")\n",
        "\n",
        "# Accuracy => 학습하지 않은 것에서 잘 나와야"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gm-othupsR3A",
        "outputId": "753978dc-0fb5-48ec-ba80-a45ae168e68d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.297005  [    0/60000]\n",
            "loss: 2.288083  [ 6400/60000]\n",
            "loss: 2.274117  [12800/60000]\n",
            "loss: 2.273103  [19200/60000]\n",
            "loss: 2.260358  [25600/60000]\n",
            "loss: 2.246846  [32000/60000]\n",
            "loss: 2.252670  [38400/60000]\n",
            "loss: 2.239069  [44800/60000]\n",
            "loss: 2.220069  [51200/60000]\n",
            "loss: 2.201971  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 49.2%, Avg loss: 0.034576 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.203372  [    0/60000]\n",
            "loss: 2.178888  [ 6400/60000]\n",
            "loss: 2.153715  [12800/60000]\n",
            "loss: 2.180137  [19200/60000]\n",
            "loss: 2.129426  [25600/60000]\n",
            "loss: 2.117247  [32000/60000]\n",
            "loss: 2.141595  [38400/60000]\n",
            "loss: 2.112052  [44800/60000]\n",
            "loss: 2.087985  [51200/60000]\n",
            "loss: 2.050860  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.6%, Avg loss: 0.032243 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.052691  [    0/60000]\n",
            "loss: 1.998588  [ 6400/60000]\n",
            "loss: 1.958560  [12800/60000]\n",
            "loss: 2.030573  [19200/60000]\n",
            "loss: 1.910345  [25600/60000]\n",
            "loss: 1.916396  [32000/60000]\n",
            "loss: 1.963524  [38400/60000]\n",
            "loss: 1.918984  [44800/60000]\n",
            "loss: 1.891936  [51200/60000]\n",
            "loss: 1.813136  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 51.7%, Avg loss: 0.028721 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.843220  [    0/60000]\n",
            "loss: 1.748146  [ 6400/60000]\n",
            "loss: 1.696072  [12800/60000]\n",
            "loss: 1.785621  [19200/60000]\n",
            "loss: 1.617585  [25600/60000]\n",
            "loss: 1.693852  [32000/60000]\n",
            "loss: 1.703126  [38400/60000]\n",
            "loss: 1.694798  [44800/60000]\n",
            "loss: 1.647286  [51200/60000]\n",
            "loss: 1.533408  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 52.5%, Avg loss: 0.024743 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.633444  [    0/60000]\n",
            "loss: 1.513170  [ 6400/60000]\n",
            "loss: 1.448856  [12800/60000]\n",
            "loss: 1.538435  [19200/60000]\n",
            "loss: 1.363723  [25600/60000]\n",
            "loss: 1.520965  [32000/60000]\n",
            "loss: 1.489123  [38400/60000]\n",
            "loss: 1.529405  [44800/60000]\n",
            "loss: 1.456680  [51200/60000]\n",
            "loss: 1.338882  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.2%, Avg loss: 0.021766 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Neural Network"
      ],
      "metadata": {
        "id": "BpPRv8nYteBo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "Jwq0OBY4sTXy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Using {} device'.format(device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiMUOR-RtizD",
        "outputId": "f03e20bf-0baa-4d98-f107-753cfe0ca263"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "xBUWPuPbto54"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NjzvUk8JttHo",
        "outputId": "45bf2cf5-3c91-4917-d95b-9138cec17a57"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device) # channel rgb면 3, 그러나 우리는 gray scale이므로 1임, (세로, 가로)\n",
        "logits = model(X)\n",
        "print(logits) # Softmax를 거치기 전이라 합이 1이 아님\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "print(pred_probab) # Softmax를 거쳐서 합이 1임\n",
        "y_pred = pred_probab.argmax(1) # 여기서 제일 큰 값은\n",
        "print(f\"Predicted class: {y_pred}\") # 3번째"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6u-FRpDUtwA7",
        "outputId": "b604a7e6-6219-4003-eb68-44c491230cda"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0000, 0.0000, 0.0000, 0.0479, 0.0000, 0.0418, 0.0000, 0.0000, 0.0253,\n",
            "         0.0262]], grad_fn=<ReluBackward0>)\n",
            "tensor([[0.0986, 0.0986, 0.0986, 0.1034, 0.0986, 0.1028, 0.0986, 0.0986, 0.1011,\n",
            "         0.1012]], grad_fn=<SoftmaxBackward0>)\n",
            "Predicted class: tensor([3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서 0. 입력\n",
        "input_image = torch.rand(3,28,28) # 채널이 3개인 이미지\n",
        "print(input_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wz5GGwGkt1ya",
        "outputId": "b2c9941e-0b77-4461-b6b1-4b2c7ae82f9e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서 1. flatten\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GssJYjBxvP7d",
        "outputId": "3f76320d-3b03-4fba-b75a-492ae0dd6690"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서 2. Linear\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N-6OYOAHvUGg",
        "outputId": "5fab3fc5-9b95-43fa-b271-0f85cebc3d7c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서 0 -> 1 -> 2\n",
        "\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwfPitHhvxec",
        "outputId": "9b1e561d-e73c-4751-b007-92f91b34026a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.1470,  0.3908, -0.4323,  0.2342,  0.1481,  0.1198,  0.1688, -0.2064,\n",
            "          0.0590, -0.3100,  0.1446,  0.1083,  0.1193, -0.2478, -0.2861,  0.1390,\n",
            "          0.1876,  0.0212,  0.4712, -0.3445],\n",
            "        [ 0.4637,  0.2263, -0.5036,  0.1986,  0.1382,  0.0208,  0.3027, -0.0782,\n",
            "          0.0818, -0.5356,  0.1430,  0.2000,  0.3346, -0.3216, -0.5069,  0.3001,\n",
            "          0.3305,  0.1154,  0.3756, -0.3675],\n",
            "        [-0.0590,  0.2807, -0.2577,  0.3472, -0.0188,  0.2627,  0.0815, -0.3782,\n",
            "         -0.1499, -0.3914,  0.1503,  0.0436,  0.0162, -0.2902, -0.3841,  0.3341,\n",
            "          0.1344,  0.0214,  0.2336, -0.0951]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.1470, 0.3908, 0.0000, 0.2342, 0.1481, 0.1198, 0.1688, 0.0000, 0.0590,\n",
            "         0.0000, 0.1446, 0.1083, 0.1193, 0.0000, 0.0000, 0.1390, 0.1876, 0.0212,\n",
            "         0.4712, 0.0000],\n",
            "        [0.4637, 0.2263, 0.0000, 0.1986, 0.1382, 0.0208, 0.3027, 0.0000, 0.0818,\n",
            "         0.0000, 0.1430, 0.2000, 0.3346, 0.0000, 0.0000, 0.3001, 0.3305, 0.1154,\n",
            "         0.3756, 0.0000],\n",
            "        [0.0000, 0.2807, 0.0000, 0.3472, 0.0000, 0.2627, 0.0815, 0.0000, 0.0000,\n",
            "         0.0000, 0.1503, 0.0436, 0.0162, 0.0000, 0.0000, 0.3341, 0.1344, 0.0214,\n",
            "         0.2336, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)\n",
        "print(input_image)\n",
        "print(logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCu2xIM6vz-4",
        "outputId": "84e261bd-8317-44f6-c446-1d9471b55ada"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.3604e-01, 5.4428e-01, 8.0915e-01,  ..., 1.8892e-02,\n",
            "          2.7146e-02, 7.7965e-01],\n",
            "         [1.2414e-01, 8.4502e-01, 3.1740e-01,  ..., 4.5744e-01,\n",
            "          2.0024e-01, 5.7610e-01],\n",
            "         [4.7088e-01, 5.5074e-01, 7.7658e-01,  ..., 7.9615e-01,\n",
            "          6.7392e-01, 3.6019e-01],\n",
            "         ...,\n",
            "         [6.3902e-01, 5.3565e-01, 6.2131e-01,  ..., 9.1288e-01,\n",
            "          6.8873e-01, 3.0337e-01],\n",
            "         [3.7434e-01, 5.3561e-01, 5.7847e-01,  ..., 3.7656e-01,\n",
            "          6.8097e-02, 6.5829e-01],\n",
            "         [9.0053e-03, 6.6731e-01, 4.5318e-01,  ..., 7.0869e-01,\n",
            "          2.9535e-01, 2.1627e-01]],\n",
            "\n",
            "        [[3.8783e-01, 7.1637e-01, 9.2699e-01,  ..., 2.6316e-02,\n",
            "          1.0120e-01, 5.8739e-01],\n",
            "         [7.9937e-01, 2.8726e-01, 7.1137e-01,  ..., 8.4997e-01,\n",
            "          1.7829e-01, 6.6541e-01],\n",
            "         [4.9522e-01, 4.2272e-01, 1.6936e-01,  ..., 6.9761e-01,\n",
            "          4.0154e-01, 3.4533e-02],\n",
            "         ...,\n",
            "         [3.1499e-01, 1.0321e-01, 6.0152e-01,  ..., 9.1505e-01,\n",
            "          1.1743e-01, 1.0583e-01],\n",
            "         [3.6006e-01, 2.1875e-02, 7.2797e-01,  ..., 5.4726e-01,\n",
            "          3.3077e-01, 3.6932e-01],\n",
            "         [7.0729e-01, 7.8878e-01, 1.7362e-01,  ..., 2.1719e-01,\n",
            "          9.0975e-01, 5.8749e-01]],\n",
            "\n",
            "        [[1.5974e-01, 5.9757e-01, 5.2140e-01,  ..., 8.2497e-01,\n",
            "          6.8057e-01, 1.2493e-01],\n",
            "         [5.6843e-01, 7.0621e-01, 6.9773e-02,  ..., 2.7061e-01,\n",
            "          4.1539e-01, 1.7418e-01],\n",
            "         [1.2499e-01, 2.2694e-01, 9.1019e-01,  ..., 6.6064e-01,\n",
            "          8.4239e-01, 3.1620e-01],\n",
            "         ...,\n",
            "         [8.7806e-01, 3.0690e-04, 8.2996e-01,  ..., 2.6161e-01,\n",
            "          9.4948e-01, 4.1240e-01],\n",
            "         [9.9900e-02, 8.2766e-01, 4.9649e-01,  ..., 4.4765e-02,\n",
            "          6.0344e-01, 6.4337e-01],\n",
            "         [9.9769e-01, 4.3749e-01, 2.2405e-01,  ..., 3.1053e-01,\n",
            "          4.3527e-01, 6.9856e-01]]])\n",
            "tensor([[ 0.0155,  0.0932, -0.1887,  0.2462,  0.0135, -0.0996, -0.1584,  0.4702,\n",
            "          0.2340,  0.4542],\n",
            "        [ 0.0309,  0.1799, -0.1334,  0.0475,  0.0235, -0.2086, -0.0861,  0.3684,\n",
            "          0.0025,  0.3163],\n",
            "        [ 0.0393,  0.0017, -0.1730,  0.1175,  0.0693, -0.1436, -0.1924,  0.3903,\n",
            "          0.0955,  0.3572]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)\n",
        "print(softmax)\n",
        "print(pred_probab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmpgSnLFwYlH",
        "outputId": "bdb429d6-6129-4c68-dd89-b98c09571227"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Softmax(dim=1)\n",
            "tensor([[0.0888, 0.0960, 0.0724, 0.1119, 0.0887, 0.0792, 0.0747, 0.1400, 0.1105,\n",
            "         0.1378],\n",
            "        [0.0962, 0.1116, 0.0816, 0.0978, 0.0955, 0.0757, 0.0855, 0.1348, 0.0935,\n",
            "         0.1279],\n",
            "        [0.0965, 0.0929, 0.0780, 0.1044, 0.0994, 0.0804, 0.0765, 0.1371, 0.1021,\n",
            "         0.1326]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "69dbhaanwzRl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}